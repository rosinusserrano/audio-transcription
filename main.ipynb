{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2f4ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/marco/MLGroup/WorkshopTranscription/.venv/lib/python3.10/site-packages/rich/live.py:260: UserWarning: install\n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/marco/MLGroup/WorkshopTranscription/.venv/lib/python3.10/site-packages/rich/live.py:260: UserWarning: install\n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/marco/MLGroup/WorkshopTranscription/.venv/lib/python3.10/site-packages/pyannote/audio/models/blocks/pooling.p\n",
       "y:103: UserWarning: std(): degrees of freedom is &lt;= 0. Correction should be strictly less than the reduction factor\n",
       "(input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1857.)\n",
       "  std = sequences.std(dim=-1, correction=1)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/marco/MLGroup/WorkshopTranscription/.venv/lib/python3.10/site-packages/pyannote/audio/models/blocks/pooling.p\n",
       "y:103: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor\n",
       "(input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1857.)\n",
       "  std = sequences.std(dim=-1, correction=1)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/marco/MLGroup/WorkshopTranscription/.venv/lib/python3.10/site-packages/rich/live.py:260: UserWarning: install\n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/marco/MLGroup/WorkshopTranscription/.venv/lib/python3.10/site-packages/rich/live.py:260: UserWarning: install\n",
       "\"ipywidgets\" for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from pyannote.audio import Pipeline\n",
    "from pyannote.audio.pipelines.utils.hook import ProgressHook\n",
    "\n",
    "HF_TOKEN = \"TOKEN_HERE\"\n",
    "\n",
    "pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization-community-1\", token=HF_TOKEN)\n",
    "\n",
    "assert pipeline is not None, \"Something happened\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    pipeline.to(torch.device(\"cuda\"))\n",
    "\n",
    "with ProgressHook() as hook:\n",
    "    waveform, sample_rate = torchaudio.load(\"./Aufzeichnung.m4a\")\n",
    "    output = pipeline({\"waveform\": waveform, \"sample_rate\": sample_rate}, hook=hook)\n",
    "    # output = pipeline(\"test.wav\", hook=hook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf21c885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['start', 'end', '__module__', '__annotations__', '__doc__', 'set_precision', '__bool__', '__post_init__', 'duration', 'middle', '__iter__', 'copy', '__contains__', '__and__', 'intersects', 'overlaps', '__or__', '__xor__', '_str_helper', '__str__', '__repr__', '_repr_png_', '__dict__', '__weakref__', '__dataclass_params__', '__dataclass_fields__', '__init__', '__eq__', '__lt__', '__le__', '__gt__', '__ge__', '__setattr__', '__delattr__', '__hash__', '__match_args__', '__new__', '__getattribute__', '__ne__', '__reduce_ex__', '__reduce__', '__subclasshook__', '__init_subclass__', '__format__', '__sizeof__', '__dir__', '__class__']\n",
      "['start', 'end', '__module__', '__annotations__', '__doc__', 'set_precision', '__bool__', '__post_init__', 'duration', 'middle', '__iter__', 'copy', '__contains__', '__and__', 'intersects', 'overlaps', '__or__', '__xor__', '_str_helper', '__str__', '__repr__', '_repr_png_', '__dict__', '__weakref__', '__dataclass_params__', '__dataclass_fields__', '__init__', '__eq__', '__lt__', '__le__', '__gt__', '__ge__', '__setattr__', '__delattr__', '__hash__', '__match_args__', '__new__', '__getattribute__', '__ne__', '__reduce_ex__', '__reduce__', '__subclasshook__', '__init_subclass__', '__format__', '__sizeof__', '__dir__', '__class__']\n"
     ]
    }
   ],
   "source": [
    "for turn, speaker in output.speaker_diarization:\n",
    "    print(turn.__dir__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea271fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2.88G/2.88G [01:47<00:00, 28.6MiB/s]\n",
      "/home/marco/MLGroup/WorkshopTranscription/.venv/lib/python3.10/site-packages/whisper/transcribe.py:132: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"large-v3\")\n",
    "\n",
    "result = model.transcribe(\"Aufzeichnung.m4a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bfa09094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 0,\n",
       "  'seek': 0,\n",
       "  'start': 0.0,\n",
       "  'end': 6.140000000000001,\n",
       "  'text': ' Okay, test one, two, three.',\n",
       "  'tokens': [50365, 1033, 11, 1500, 472, 11, 732, 11, 1045, 13, 50672],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.48067413676868787,\n",
       "  'compression_ratio': 1.0,\n",
       "  'no_speech_prob': 0.0120825981721282},\n",
       " {'id': 1,\n",
       "  'seek': 0,\n",
       "  'start': 6.140000000000001,\n",
       "  'end': 8.5,\n",
       "  'text': ' And test four, five, six.',\n",
       "  'tokens': [50672, 400, 1500, 1451, 11, 1732, 11, 2309, 13, 50790],\n",
       "  'temperature': 0.0,\n",
       "  'avg_logprob': -0.48067413676868787,\n",
       "  'compression_ratio': 1.0,\n",
       "  'no_speech_prob': 0.0120825981721282}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"segments\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b5ac7819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 00:00:01.785 -->  00:00:04.367] SPEAKER_01\n",
      "[ 00:00:05.819 -->  00:00:08.451] SPEAKER_00\n"
     ]
    }
   ],
   "source": [
    "for turn, speaker in output.speaker_diarization:\n",
    "    print(turn, speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "426855bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription = \"\"\n",
    "\n",
    "whisper_index = 0\n",
    "\n",
    "for turn, speaker in output.speaker_diarization:\n",
    "    transcription += f\"[{speaker}]\\n\"\n",
    "    found_end = False\n",
    "    while not found_end:\n",
    "        current_segment = result[\"segments\"][whisper_index]\n",
    "        \n",
    "        w_start = current_segment[\"start\"]\n",
    "        w_end = current_segment[\"end\"]\n",
    "\n",
    "        p_end = turn.end\n",
    "\n",
    "        if w_end < p_end:\n",
    "            transcription += f\"{current_segment['text']} \"\n",
    "            whisper_index += 1\n",
    "\n",
    "        elif w_end - p_end < p_end - w_start:\n",
    "            transcription += f\"{current_segment['text']}\\n\\n\"\n",
    "            whisper_index += 1\n",
    "            found_end = True\n",
    "\n",
    "        else:\n",
    "            transcription += \"\\n\"\n",
    "            found_end = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed2c9538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SPEAKER_01]\n",
      " Okay, test one, two, three.\n",
      "\n",
      "[SPEAKER_00]\n",
      " And test four, five, six.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(transcription)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshoptranscription (3.10.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
